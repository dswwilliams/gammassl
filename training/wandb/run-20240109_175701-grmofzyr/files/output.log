xFormers not available
xFormers not available
  0%|                                                                                                                                 | 0/1 [00:00<?, ?it/s]
Device:  cpu
No. of training examples per epoch: 44
No. of iterations per epoch: 2.0
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_imgs shape: torch.Size([24, 3, 224, 224])
no grad
  0%|                                                                                                                                 | 0/1 [00:07<?, ?it/s]
Traceback (most recent call last):
  File "/Users/dw/code/pytorch/gammassl_public/training/train.py", line 175, in <module>
    trainer.train()
  File "/Users/dw/code/pytorch/gammassl_public/training/../training/base_trainer.py", line 196, in train
    losses, metrics = self._train_models(labelled_dict, raw_dict)
  File "/Users/dw/code/pytorch/gammassl_public/training/gammassl_trainer.py", line 45, in _train_models
    m2f_losses, sup_metrics = self.perform_labelled_task(labelled_dict)
  File "/Users/dw/code/pytorch/gammassl_public/training/gammassl_trainer.py", line 94, in perform_labelled_task
    m2f_outputs = self.segment_labelled_imgs(labelled_imgs, labelled_crop_boxes_A)
  File "/Users/dw/code/pytorch/gammassl_public/training/gammassl_trainer.py", line 189, in segment_labelled_imgs
    output = self.model.seg_net.extract_m2f_output(labelled_imgs_A)
  File "/Users/dw/miniconda3/envs/dinov2/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'ViTDINOSegNet' object has no attribute 'extract_m2f_output'