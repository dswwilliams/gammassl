Device:  cpu
relative_upsample_factors [1.0, 2.0, 2.0]
relative_downsample_factors [2]
384
No. of training examples per epoch: 44
No. of iterations per epoch: 2.0
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
labelled_dict:  dict_keys(['box_A', 'img', 'label'])
raw_dict:  dict_keys(['img_1', 'img_2', 'box_A', 'box_B'])
xFormers not available
xFormers not available
  0%|                                                                                                                                 | 0/1 [00:00<?, ?it/s]
no grad
  0%|                                                                                                                                 | 0/1 [00:09<?, ?it/s]
Traceback (most recent call last):
  File "/Users/dw/code/pytorch/gammassl_public/training/train.py", line 175, in <module>
    trainer.train()
  File "/Users/dw/code/pytorch/gammassl_public/training/../training/base_trainer.py", line 196, in train
    losses, metrics = self._train_models(labelled_dict, raw_dict)
  File "/Users/dw/code/pytorch/gammassl_public/training/gammassl_trainer.py", line 44, in _train_models
    m2f_losses, sup_metrics = self.perform_labelled_task(labelled_dict)
  File "/Users/dw/code/pytorch/gammassl_public/training/gammassl_trainer.py", line 96, in perform_labelled_task
    losses, metrics = self.losses.calculate_m2f_losses(m2f_outputs, labels, labelled_crop_boxes_A)
AttributeError: 'Trainer' object has no attribute 'losses'